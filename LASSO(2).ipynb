import numpy as np
import pandas as pd
from sklearn.model_selection import LeaveOneOut
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import os
import warnings



data = pd.read_csv('')

print(f"Dataset shape: {data.shape}")
print(f"Dataset columns: {data.columns.tolist()}")
print(f"Dataset preview:")
print(data)


topological_indices = []

properties = []


available_properties = [prop for prop in properties if prop in data.columns]
print(f"\nAvailable properties: {available_properties}")
print(f"Available topological indices: {[idx for idx in topological_indices if idx in data.columns]}")


alpha_values = [0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0]
max_iter_values = [1000, 5000]  


scaling_options = [True, False]  

all_results = []
detailed_results = {}


output_dir = ''
os.makedirs(output_dir, exist_ok=True)

print("\n" + "=" * 60)
print("LASSO REGRESSION ANALYSIS FOR SMALL DATASET (10 SAMPLES)")
print("Using Leave-One-Out Cross-Validation")
print("Testing both SCALED and UNSCALED data")
print("=" * 60)

for prop_idx, prop in enumerate(available_properties, 1):
    print(f"\nAnalyzing Property {prop_idx}: {prop}")
    print("-" * 40)
    
   
    available_indices = [idx for idx in topological_indices if idx in data.columns]
    prop_data = data[[prop] + available_indices].dropna()
    n_samples = len(prop_data)
    
    print(f"  Clean samples for {prop}: {n_samples}")
    
    if n_samples < 3:
        print(f"  Insufficient data for {prop} (need at least 3 samples)")
        continue
    
    property_results = []
    
    for index in available_indices:
        print(f"  Testing topological index: {index}")
        
        X = prop_data[[index]].values
        y = prop_data[prop].values
        
       
        for use_scaling in scaling_options:
            scaling_label = "Scaled" if use_scaling else "Unscaled"
            print(f"    Testing {scaling_label} data...")
            
            best_loo_score = -np.inf
            best_params = None
            best_predictions = None
            best_alpha_path = None
            
            
            for alpha in alpha_values:
                for max_iter in max_iter_values:
                   
                    loo = LeaveOneOut()
                    loo_predictions = []
                    loo_actuals = []
                    converged_count = 0
                    
                    try:
                        for train_idx, test_idx in loo.split(X):
                            X_train, X_test = X[train_idx], X[test_idx]
                            y_train, y_test = y[train_idx], y[test_idx]
                            
                            
                            if use_scaling:
                                scaler = StandardScaler()
                                X_train_processed = scaler.fit_transform(X_train)
                                X_test_processed = scaler.transform(X_test)
                            else:
                                X_train_processed = X_train
                                X_test_processed = X_test
                            
                            lasso = Lasso(
                                alpha=alpha, 
                                max_iter=max_iter,
                                random_state=42,
                                selection='random'  
                            )
                            lasso.fit(X_train_processed, y_train)
                            
                           
                            if hasattr(lasso, 'n_iter_') and lasso.n_iter_ < max_iter:
                                converged_count += 1
                            
                            pred = lasso.predict(X_test_processed)[0]
                            loo_predictions.append(pred)
                            loo_actuals.append(y_test[0])
                        
                        
                        if len(loo_predictions) > 1:
                            loo_r2 = r2_score(loo_actuals, loo_predictions)
                            loo_rmse = np.sqrt(mean_squared_error(loo_actuals, loo_predictions))
                            loo_mae = mean_absolute_error(loo_actuals, loo_predictions)
                            
                            convergence_rate = converged_count / len(loo_predictions)
                            
                            if loo_r2 > best_loo_score and convergence_rate >= 0.5:  
                                best_loo_score = loo_r2
                                best_params = {
                                    'alpha': alpha, 
                                    'max_iter': max_iter,
                                    'convergence_rate': convergence_rate
                                }
                                best_predictions = loo_predictions.copy()
                                best_rmse = loo_rmse
                                best_mae = loo_mae
                        
                    except Exception as e:
                        print(f"      Error with alpha={alpha}, max_iter={max_iter}: {str(e)[:50]}...")
                        continue
            
            if best_params is not None:
                
                if use_scaling:
                    scaler_final = StandardScaler()
                    X_processed = scaler_final.fit_transform(X)
                else:
                    X_processed = X
                
                final_lasso = Lasso(
                    alpha=best_params['alpha'],
                    max_iter=best_params['max_iter'],
                    random_state=42,
                    selection='random'
                )
                final_lasso.fit(X_processed, y)
                final_predictions = final_lasso.predict(X_processed)
                
                
                full_r2 = r2_score(y, final_predictions)
                full_rmse = np.sqrt(mean_squared_error(y, final_predictions))
                full_mae = mean_absolute_error(y, final_predictions)
                
                
                coef_value = final_lasso.coef_[0]
                intercept_value = final_lasso.intercept_
                
                
                feature_selected = abs(coef_value) > 1e-8
                
                index_result = {
                    'Property': prop,
                    'Topological_Index': index,
                    'Scaling': scaling_label,
                    'LOOCV_R2': best_loo_score,
                    'LOOCV_RMSE': best_rmse,
                    'LOOCV_MAE': best_mae,
                    'Full_Data_R2': full_r2,
                    'Full_Data_RMSE': full_rmse,
                    'Full_Data_MAE': full_mae,
                    'Best_Alpha': best_params['alpha'],
                    'Best_Max_Iter': best_params['max_iter'],
                    'Convergence_Rate': best_params['convergence_rate'],
                    'Coefficient': coef_value,
                    'Intercept': intercept_value,
                    'Feature_Selected': feature_selected,
                    'N_Samples': n_samples
                }
                property_results.append(index_result)
                
                print(f"      {scaling_label}:")
                print(f"        LOOCV - R²={best_loo_score:.4f}, RMSE={best_rmse:.4f}, MAE={best_mae:.4f}")
                print(f"        Full  - R²={full_r2:.4f}, RMSE={full_rmse:.4f}, MAE={full_mae:.4f}")
                print(f"        Best params: α={best_params['alpha']}, max_iter={best_params['max_iter']}")
                print(f"        Coefficient: {coef_value:.4f}, Selected: {feature_selected}")
                print(f"        Convergence rate: {best_params['convergence_rate']:.2f}")
                
                
                pred_df = pd.DataFrame({
                    'Sample_Index': range(len(y)),
                    f'{prop}_Actual': y,
                    f'{prop}_LOOCV_Predicted': best_predictions,
                    f'{prop}_Full_Predicted': final_predictions,
                    f'{prop}_LOOCV_Residuals': np.array(loo_actuals) - np.array(best_predictions),
                    f'{prop}_Full_Residuals': y - final_predictions,
                    f'{prop}_Coefficient': [coef_value] * len(y),
                    f'{prop}_Intercept': [intercept_value] * len(y),
                    f'{prop}_Scaling': [scaling_label] * len(y)
                })
                pred_filename = f'{output_dir}/Lasso_{prop}_{index}_{scaling_label}_predictions.csv'
                pred_df.to_csv(pred_filename, index=False)
                
            else:
                print(f"      {scaling_label}: No valid model found (convergence issues)")
    
    
    if property_results:
        detailed_results[prop] = property_results
        
        
        best_result = max(property_results, key=lambda x: x['LOOCV_R2'])
        all_results.append(best_result)
        
        print(f"\n  BEST for {prop}: {best_result['Topological_Index']} ({best_result['Scaling']})")
        print(f"    LOOCV R²: {best_result['LOOCV_R2']:.4f}")
        print(f"    LOOCV RMSE: {best_result['LOOCV_RMSE']:.4f}")
        print(f"    LOOCV MAE: {best_result['LOOCV_MAE']:.4f}")
        print(f"    Feature coefficient: {best_result['Coefficient']:.4f}")
        
       
        prop_df = pd.DataFrame(property_results)
        prop_filename = f'{output_dir}/Lasso_{prop}'
        prop_df.to_csv(prop_filename, index=False)
        print(f"    All results saved to: {prop_filename}")
    
    else:
        print(f"  No valid results for {prop}")


print("\n" + "=" * 60)
print("FINAL SUMMARY")
print("=" * 60)

if all_results:
    summary_df = pd.DataFrame(all_results)
    
    print("\nBest Index for Each Property (based on LOOCV):")
    print("-" * 60)
    for _, row in summary_df.iterrows():
        selected_status = "✓" if row['Feature_Selected'] else "✗"
        print(f"{row['Property']:>12}: {row['Topological_Index']:>3} ({row['Scaling']:>8}) "
              f"(R²={row['LOOCV_R2']:6.3f}, RMSE={row['LOOCV_RMSE']:6.3f}, "
              f"MAE={row['LOOCV_MAE']:6.3f}) [α={row['Best_Alpha']:.3f}, {selected_status}]")
    
    
    summary_filename = f'{output_dir}'
    summary_df.to_csv(summary_filename, index=False)
    print(f"\nSummary saved to: {summary_filename}")
    
    
    print(f"\nOverall Statistics Across All Properties:")
    print(f"  Mean LOOCV R²: {summary_df['LOOCV_R2'].mean():.4f}")
    print(f"  Mean LOOCV RMSE: {summary_df['LOOCV_RMSE'].mean():.4f}")
    print(f"  Mean LOOCV MAE: {summary_df['LOOCV_MAE'].mean():.4f}")
    print(f"  Properties analyzed: {len(summary_df)}")
    
    
    print(f"\nScaling Preference Analysis:")
    scaling_counts = summary_df['Scaling'].value_counts()
    for scaling_type, count in scaling_counts.items():
        print(f"  {scaling_type}: {count} properties ({count/len(summary_df)*100:.1f}%)")
   
    print(f"\nOptimal Alpha Distribution:")
    alpha_counts = summary_df['Best_Alpha'].value_counts().sort_index()
    for alpha, count in alpha_counts.items():
        print(f"  α={alpha}: {count} properties")
    

    selected_count = summary_df['Feature_Selected'].sum()
    total_count = len(summary_df)
    print(f"\nFeature Selection Analysis:")
    print(f"  Features selected: {selected_count}/{total_count} ({selected_count/total_count*100:.1f}%)")
    print(f"  Features zeroed out: {total_count-selected_count}/{total_count} ({(total_count-selected_count)/total_count*100:.1f}%)")
    
    
    print(f"\nConvergence Analysis:")
    mean_convergence = summary_df['Convergence_Rate'].mean()
    print(f"  Mean convergence rate: {mean_convergence:.2f}")
    
   
    all_detailed = []
    for prop, results in detailed_results.items():
        all_detailed.extend(results)
    
    if all_detailed:
        comprehensive_df = pd.DataFrame(all_detailed)
        comprehensive_filename = f'{output_dir}'
        comprehensive_df.to_csv(comprehensive_filename, index=False)
        print(f"  Comprehensive results: {comprehensive_filename}")
        
        print(f"\nScaling Effects Analysis:")
        scaled_results = comprehensive_df[comprehensive_df['Scaling'] == 'Scaled']
        unscaled_results = comprehensive_df[comprehensive_df['Scaling'] == 'Unscaled']
        
        if len(scaled_results) > 0 and len(unscaled_results) > 0:
            print(f"  Scaled data - Mean R²: {scaled_results['LOOCV_R2'].mean():.4f}")
            print(f"  Unscaled data - Mean R²: {unscaled_results['LOOCV_R2'].mean():.4f}")
            print(f"  Scaled data - Mean |coefficient|: {scaled_results['Coefficient'].abs().mean():.4f}")
            print(f"  Unscaled data - Mean |coefficient|: {unscaled_results['Coefficient'].abs().mean():.4f}")
        
        
        print(f"\nRegularization Analysis Across All Property-Index Combinations:")
        print(f"  Most common alpha values: {comprehensive_df['Best_Alpha'].mode().tolist()}")
        print(f"  Features selected: {comprehensive_df['Feature_Selected'].sum()}/{len(comprehensive_df)}")
        print(f"  Mean |coefficient|: {comprehensive_df['Coefficient'].abs().mean():.4f}")
        print(f"  Coefficient std: {comprehensive_df['Coefficient'].std():.4f}")

else:
    print("No valid results found!")
    print("\nPossible issues:")
    print("1. Property columns don't exist in your CSV")
    print("2. Too many missing values")
    print("3. Convergence issues with Lasso")

print(f"\nAll files saved in: {output_dir}")
print("\nLasso Notes for 10-sample datasets:")
print("- Both scaled and unscaled data tested")
print("- Feature scaling applied using StandardScaler when requested")
print("- Wide alpha range tested (0.001 to 10.0)")
print("- Convergence monitoring included")
print("- Feature selection information provided")
print("- LOOCV provides unbiased evaluation")
print("- Coefficients show feature importance and direction")
print("- Scaling preference analysis included")
print("\nLasso Advantages:")
print("- Automatic feature selection")
print("- Handles multicollinearity")
print("- Interpretable coefficients")
print("- Less prone to overfitting")
print("- Can work with both scaled and unscaled data")
print("\nAnalysis complete!")