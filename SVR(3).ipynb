import numpy as np
import pandas as pd
from sklearn.model_selection import LeaveOneOut
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import os
import warnings


data = pd.read_csv('')

print(f"Dataset shape: {data.shape}")
print(f"Dataset columns: {data.columns.tolist()}")
print(f"Dataset preview:")
print(data)

topological_indices = []

properties = []

available_properties = [prop for prop in properties if prop in data.columns]
print(f"\nAvailable properties: {available_properties}")
print(f"Available topological indices: {[idx for idx in topological_indices if idx in data.columns]}")

C_values = [1, 10, 100]
epsilon_values = [0.1, 0.5]


all_results = []
detailed_results = {}


output_dir = ''
os.makedirs(output_dir, exist_ok=True)

print("\n" + "=" * 60)
print("SVR ANALYSIS FOR SMALL DATASET (10 SAMPLES)")
print("Using Leave-One-Out Cross-Validation")
print("Testing both SCALED and UNSCALED data")
print("=" * 60)

def evaluate_svr_with_scaling(X, y, scaling_type="unscaled"):
    
    best_loo_score = -np.inf
    best_params = None
    best_predictions = None
    best_rmse = None
    best_mae = None
    
   
    for C in C_values:
        for epsilon in epsilon_values:
            try:
                
                loo = LeaveOneOut()
                loo_predictions = []
                loo_actuals = []
                
                for train_idx, test_idx in loo.split(X):
                    X_train_loo, X_test_loo = X[train_idx], X[test_idx]
                    y_train_loo, y_test_loo = y[train_idx], y[test_idx]
                    
                    # Apply scaling if requested
                    if scaling_type == "scaled":
                        scaler = StandardScaler()
                        X_train_loo_scaled = scaler.fit_transform(X_train_loo)
                        X_test_loo_scaled = scaler.transform(X_test_loo)
                    else:
                        X_train_loo_scaled = X_train_loo
                        X_test_loo_scaled = X_test_loo
                    
                    
                    svr_temp = SVR(kernel='rbf', C=C, epsilon=epsilon, gamma='scale')
                    svr_temp.fit(X_train_loo_scaled, y_train_loo)
                    
                    pred = svr_temp.predict(X_test_loo_scaled)[0]
                    loo_predictions.append(pred)
                    loo_actuals.append(y_test_loo[0])
                
                
                if len(loo_predictions) > 1:
                    loo_r2 = r2_score(loo_actuals, loo_predictions)
                    loo_rmse = np.sqrt(mean_squared_error(loo_actuals, loo_predictions))
                    loo_mae = mean_absolute_error(loo_actuals, loo_predictions)
                    
                    if loo_r2 > best_loo_score:
                        best_loo_score = loo_r2
                        best_params = {'C': C, 'epsilon': epsilon}
                        best_predictions = loo_predictions.copy()
                        best_rmse = loo_rmse
                        best_mae = loo_mae
                
            except Exception as e:
                continue
    
    if best_params is not None:
        return {
            'loo_r2': best_loo_score,
            'loo_rmse': best_rmse,
            'loo_mae': best_mae,
            'best_params': best_params,
            'predictions': best_predictions
        }
    else:
        return None

for prop_idx, prop in enumerate(available_properties, 1):
    print(f"\nAnalyzing Property {prop_idx}: {prop}")
    print("-" * 40)
    
    
    available_indices = [idx for idx in topological_indices if idx in data.columns]
    prop_data = data[[prop] + available_indices].dropna()
    n_samples = len(prop_data)
    
    print(f"  Clean samples for {prop}: {n_samples}")
    
    if n_samples < 3:
        print(f"  Insufficient data for {prop} (need at least 3 samples)")
        continue
    
    property_results = []
    
    for index in available_indices:
        print(f"  Testing topological index: {index}")
        
        X = prop_data[[index]].values
        y = prop_data[prop].values
        
       
        results_unscaled = evaluate_svr_with_scaling(X, y, "unscaled")
        results_scaled = evaluate_svr_with_scaling(X, y, "scaled")
        
       
        best_scaling = None
        best_result = None
        
        if results_unscaled is not None and results_scaled is not None:
            if results_unscaled['loo_r2'] >= results_scaled['loo_r2']:
                best_scaling = "Unscaled"
                best_result = results_unscaled
            else:
                best_scaling = "Scaled"
                best_result = results_scaled
        elif results_unscaled is not None:
            best_scaling = "Unscaled"
            best_result = results_unscaled
        elif results_scaled is not None:
            best_scaling = "Scaled"
            best_result = results_scaled
        
        if best_result is not None:
            
            if best_scaling == "Scaled":
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
                final_svr = SVR(
                    kernel='rbf', 
                    C=best_result['best_params']['C'], 
                    epsilon=best_result['best_params']['epsilon'], 
                    gamma='scale'
                )
                final_svr.fit(X_scaled, y)
                final_predictions = final_svr.predict(X_scaled)
            else:
                final_svr = SVR(
                    kernel='rbf', 
                    C=best_result['best_params']['C'], 
                    epsilon=best_result['best_params']['epsilon'], 
                    gamma='scale'
                )
                final_svr.fit(X, y)
                final_predictions = final_svr.predict(X)
            
           
            full_r2 = r2_score(y, final_predictions)
            full_rmse = np.sqrt(mean_squared_error(y, final_predictions))
            full_mae = mean_absolute_error(y, final_predictions)
            
            index_result = {
                'Property': prop,
                'Topological_Index': index,
                'Scaling': best_scaling,
                'LOOCV_R2': best_result['loo_r2'],
                'LOOCV_RMSE': best_result['loo_rmse'],
                'LOOCV_MAE': best_result['loo_mae'],
                'Full_Data_R2': full_r2,
                'Full_Data_RMSE': full_rmse,
                'Full_Data_MAE': full_mae,
                'Best_C': best_result['best_params']['C'],
                'Best_Epsilon': best_result['best_params']['epsilon'],
                'N_Samples': n_samples
            }
            property_results.append(index_result)
            
            print(f"    {index} ({best_scaling}):")
            print(f"      LOOCV - R²={best_result['loo_r2']:.4f}, RMSE={best_result['loo_rmse']:.4f}, MAE={best_result['loo_mae']:.4f}")
            print(f"      Full  - R²={full_r2:.4f}, RMSE={full_rmse:.4f}, MAE={full_mae:.4f}")
            print(f"      Best params: C={best_result['best_params']['C']}, ε={best_result['best_params']['epsilon']}")
          
            if results_unscaled is not None and results_scaled is not None:
                print(f"      Comparison - Unscaled R²: {results_unscaled['loo_r2']:.4f}, Scaled R²: {results_scaled['loo_r2']:.4f}")
            
            
            pred_df = pd.DataFrame({
                'Sample_Index': range(len(y)),
                f'{prop}_Actual': y,
                f'{prop}_LOOCV_Predicted': best_result['predictions'],
                f'{prop}_Full_Predicted': final_predictions,
                f'{prop}_LOOCV_Residuals': np.array(y) - np.array(best_result['predictions']),
                f'{prop}_Full_Residuals': y - final_predictions,
                'Scaling_Used': [best_scaling] * len(y)
            })
            pred_filename = f'{output_dir}/SVR_{prop}_{index}_{best_scaling.lower()}_predictions.csv'
            pred_df.to_csv(pred_filename, index=False)
            
        else:
            print(f"    {index}: No valid model found (both scaled and unscaled failed)")
    
  
    if property_results:
        detailed_results[prop] = property_results
        
        
        best_result = max(property_results, key=lambda x: x['LOOCV_R2'])
        all_results.append(best_result)
        
        print(f"\n  BEST for {prop}: {best_result['Topological_Index']} ({best_result['Scaling']})")
        print(f"    LOOCV R²: {best_result['LOOCV_R2']:.4f}")
        print(f"    LOOCV RMSE: {best_result['LOOCV_RMSE']:.4f}")
        print(f"    LOOCV MAE: {best_result['LOOCV_MAE']:.4f}")
        
        
        prop_df = pd.DataFrame(property_results)
        prop_filename = f'{output_dir}/SVR_{prop}
        prop_df.to_csv(prop_filename, index=False)
        print(f"    All results saved to: {prop_filename}")
    
    else:
        print(f"  No valid results for {prop}")


print("\n" + "=" * 60)
print("FINAL SUMMARY")
print("=" * 60)

if all_results:
    summary_df = pd.DataFrame(all_results)
    
    print("\nBest Index for Each Property (based on LOOCV):")
    print("-" * 60)
    for _, row in summary_df.iterrows():
        print(f"{row['Property']:>12}: {row['Topological_Index']:>3} ({row['Scaling']:>8}) "
              f"(R²={row['LOOCV_R2']:6.3f}, RMSE={row['LOOCV_RMSE']:6.3f}, "
              f"MAE={row['LOOCV_MAE']:6.3f})")
    
    
    summary_filename = f'{output_dir}'
    summary_df.to_csv(summary_filename, index=False)
    print(f"\nSummary saved to: {summary_filename}")
    
   
    scaling_counts = summary_df['Scaling'].value_counts()
    print(f"\nScaling Usage Summary:")
    for scaling_type, count in scaling_counts.items():
        print(f"  {scaling_type}: {count} properties ({count/len(summary_df)*100:.1f}%)")
    
   
    print(f"\nOverall Statistics Across All Properties:")
    print(f"  Mean LOOCV R²: {summary_df['LOOCV_R2'].mean():.4f}")
    print(f"  Mean LOOCV RMSE: {summary_df['LOOCV_RMSE'].mean():.4f}")
    print(f"  Mean LOOCV MAE: {summary_df['LOOCV_MAE'].mean():.4f}")
    print(f"  Properties analyzed: {len(summary_df)}")
    
    
    all_detailed = []
    for prop, results in detailed_results.items():
        all_detailed.extend(results)
    
    if all_detailed:
        comprehensive_df = pd.DataFrame(all_detailed)
        comprehensive_filename = f'{output_dir}'
        comprehensive_df.to_csv(comprehensive_filename, index=False)
        print(f"  Comprehensive results: {comprehensive_filename}")

else:
    print("No valid results found!")
    print("\nPossible issues:")
    print("1. Property columns don't exist in your CSV")
    print("2. Too many missing values")
    print("3. Data quality issues")

print(f"\nAll files saved in: {output_dir}")
print("\nFor 10-sample datasets, LOOCV provides the most reliable evaluation.")
print("Full data R² will be optimistically biased - use LOOCV metrics for model comparison.")
print("\nScaling Analysis:")
print("- StandardScaler (z-score normalization) was tested alongside unscaled data")
print("- The better performing approach was automatically selected for each index-property pair")
print("- Results show which scaling approach worked best for each combination")
print("\nAnalysis complete!")