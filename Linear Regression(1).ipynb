import numpy as np
import pandas as pd
from sklearn.model_selection import LeaveOneOut
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from scipy import stats
import os
import warnings


data = pd.read_csv('')

print(f"Dataset shape: {data.shape}")
print(f"Dataset columns: {data.columns.tolist()}")
print(f"Dataset preview:")
print(data)


topological_indices = []

properties = []


available_properties = [prop for prop in properties if prop in data.columns]
print(f"\nAvailable properties: {available_properties}")
print(f"Available topological indices: {[idx for idx in topological_indices if idx in data.columns]}")


scaling_options = [True, False] 

all_results = []
detailed_results = {}


output_dir = ''
os.makedirs(output_dir, exist_ok=True)

print("\n" + "=" * 60)
print("LINEAR REGRESSION ANALYSIS FOR SMALL DATASET (10 SAMPLES)")
print("Using Leave-One-Out Cross-Validation")
print("=" * 60)

for prop_idx, prop in enumerate(available_properties, 1):
    print(f"\nAnalyzing Property {prop_idx}: {prop}")
    print("-" * 40)
    
 
    available_indices = [idx for idx in topological_indices if idx in data.columns]
    prop_data = data[[prop] + available_indices].dropna()
    n_samples = len(prop_data)
    
    print(f"  Clean samples for {prop}: {n_samples}")
    
    if n_samples < 3:
        print(f"  Insufficient data for {prop} (need at least 3 samples)")
        continue
    
    property_results = []
    
    for index in available_indices:
        print(f"  Testing topological index: {index}")
        
        X = prop_data[[index]].values
        y = prop_data[prop].values
        
        best_loo_score = -np.inf
        best_params = None
        best_predictions = None
        best_stats = None
        
        
        for use_scaling in scaling_options:
        
            if use_scaling:
                scaler = StandardScaler()
                X_processed = scaler.fit_transform(X)
                scaling_label = "Scaled"
            else:
                X_processed = X.copy()
                scaling_label = "Unscaled"
            
            
            loo = LeaveOneOut()
            loo_predictions = []
            loo_actuals = []
            coefficients = []
            intercepts = []
            
            try:
                for train_idx, test_idx in loo.split(X_processed):
                    X_train_loo, X_test_loo = X_processed[train_idx], X_processed[test_idx]
                    y_train_loo, y_test_loo = y[train_idx], y[test_idx]
                    
                    
                    if use_scaling:
                        scaler_temp = StandardScaler()
                        X_train_scaled = scaler_temp.fit_transform(X[train_idx])
                        X_test_scaled = scaler_temp.transform(X[test_idx])
                    else:
                        X_train_scaled = X[train_idx]
                        X_test_scaled = X[test_idx]
                    
                    lr = LinearRegression()
                    lr.fit(X_train_scaled, y_train_loo)
                    
                    pred = lr.predict(X_test_scaled)[0]
                    loo_predictions.append(pred)
                    loo_actuals.append(y_test_loo[0])
                    coefficients.append(lr.coef_[0])
                    intercepts.append(lr.intercept_)
                
               
                if len(loo_predictions) > 1:
                    loo_r2 = r2_score(loo_actuals, loo_predictions)
                    loo_rmse = np.sqrt(mean_squared_error(loo_actuals, loo_predictions))
                    loo_mae = mean_absolute_error(loo_actuals, loo_predictions)
                    
                    
                    mean_coef = np.mean(coefficients)
                    std_coef = np.std(coefficients)
                    mean_intercept = np.mean(intercepts)
                    
                    if loo_r2 > best_loo_score:
                        best_loo_score = loo_r2
                        best_params = {
                            'scaling': use_scaling,
                            'scaling_label': scaling_label
                        }
                        best_predictions = loo_predictions.copy()
                        best_rmse = loo_rmse
                        best_mae = loo_mae
                        best_stats = {
                            'mean_coefficient': mean_coef,
                            'std_coefficient': std_coef,
                            'mean_intercept': mean_intercept,
                            'coefficients': coefficients,
                            'intercepts': intercepts
                        }
                
            except Exception as e:
                print(f"    Error with scaling={use_scaling}: {str(e)[:50]}...")
                continue
        
        
        if best_params is not None:
            
            if best_params['scaling']:
                scaler_final = StandardScaler()
                X_final = scaler_final.fit_transform(X)
            else:
                X_final = X.copy()
            
            final_lr = LinearRegression()
            final_lr.fit(X_final, y)
            final_predictions = final_lr.predict(X_final)
            
           
            full_r2 = r2_score(y, final_predictions)
            full_rmse = np.sqrt(mean_squared_error(y, final_predictions))
            full_mae = mean_absolute_error(y, final_predictions)
            
           
            try:
               
                corr_coef, p_value = stats.pearsonr(X.flatten(), y)
                
                
                if len(X) > 2:
                    residuals = y - final_predictions
                    mse = np.mean(residuals**2)
                    se_coef = np.sqrt(mse / np.sum((X.flatten() - np.mean(X.flatten()))**2))
                    t_stat = final_lr.coef_[0] / se_coef if se_coef > 0 else 0
                   
                    degrees_freedom = len(X) - 2
                    if degrees_freedom > 0:
                        p_value_coef = 2 * (1 - stats.t.cdf(abs(t_stat), degrees_freedom))
                    else:
                        p_value_coef = np.nan
                else:
                    t_stat = np.nan
                    p_value_coef = np.nan
                    
            except:
                corr_coef, p_value, t_stat, p_value_coef = np.nan, np.nan, np.nan, np.nan
            
            index_result = {
                'Property': prop,
                'Topological_Index': index,
                'LOOCV_R2': best_loo_score,
                'LOOCV_RMSE': best_rmse,
                'LOOCV_MAE': best_mae,
                'Full_Data_R2': full_r2,
                'Full_Data_RMSE': full_rmse,
                'Full_Data_MAE': full_mae,
                'Scaling_Used': best_params['scaling'],
                'Scaling_Label': best_params['scaling_label'],
                'Final_Coefficient': final_lr.coef_[0],
                'Final_Intercept': final_lr.intercept_,
                'Mean_LOOCV_Coefficient': best_stats['mean_coefficient'],
                'Std_LOOCV_Coefficient': best_stats['std_coefficient'],
                'Pearson_Correlation': corr_coef,
                'Correlation_P_Value': p_value,
                'Coefficient_T_Stat': t_stat,
                'Coefficient_P_Value': p_value_coef,
                'N_Samples': n_samples
            }
            property_results.append(index_result)
            
            print(f"    {index} ({best_params['scaling_label']}):")
            print(f"      LOOCV - R²={best_loo_score:.4f}, RMSE={best_rmse:.4f}, MAE={best_mae:.4f}")
            print(f"      Full  - R²={full_r2:.4f}, RMSE={full_rmse:.4f}, MAE={full_mae:.4f}")
            print(f"      Coefficient: {final_lr.coef_[0]:.4f} ± {best_stats['std_coefficient']:.4f}")
            print(f"      Intercept: {final_lr.intercept_:.4f}")
            print(f"      Correlation: r={corr_coef:.4f}, p={p_value:.4f}")
            
            
            pred_df = pd.DataFrame({
                'Sample_Index': range(len(y)),
                f'{prop}_Actual': y,
                f'{prop}_LOOCV_Predicted': best_predictions,
                f'{prop}_Full_Predicted': final_predictions,
                f'{prop}_LOOCV_Residuals': np.array(loo_actuals) - np.array(best_predictions),
                f'{prop}_Full_Residuals': y - final_predictions,
                f'{prop}_Coefficient': [final_lr.coef_[0]] * len(y),
                f'{prop}_Intercept': [final_lr.intercept_] * len(y),
                f'{prop}_LOOCV_Coefficients': best_stats['coefficients'] + [np.nan] * (len(y) - len(best_stats['coefficients']))
            })
            pred_filename = f'{output_dir}/LinearReg_{prop}_{index}'
            pred_df.to_csv(pred_filename, index=False)
            
        else:
            print(f"    {index}: No valid model found")
    
   
    if property_results:
        detailed_results[prop] = property_results
        
        best_result = max(property_results, key=lambda x: x['LOOCV_R2'])
        all_results.append(best_result)
        
        print(f"\n  BEST for {prop}: {best_result['Topological_Index']} ({best_result['Scaling_Label']})")
        print(f"    LOOCV R²: {best_result['LOOCV_R2']:.4f}")
        print(f"    LOOCV RMSE: {best_result['LOOCV_RMSE']:.4f}")
        print(f"    LOOCV MAE: {best_result['LOOCV_MAE']:.4f}")
        print(f"    Equation: y = {best_result['Final_Coefficient']:.4f}*x + {best_result['Final_Intercept']:.4f}")
        
        
        prop_df = pd.DataFrame(property_results)
        prop_filename = f'{output_dir}/LinearReg_{prop}'
        prop_df.to_csv(prop_filename, index=False)
        print(f"    All results saved to: {prop_filename}")
    
    else:
        print(f"  No valid results for {prop}")


print("\n" + "=" * 60)
print("FINAL SUMMARY")
print("=" * 60)

if all_results:
    summary_df = pd.DataFrame(all_results)
    
    print("\nBest Index for Each Property (based on LOOCV):")
    print("-" * 70)
    for _, row in summary_df.iterrows():
        significance = "**" if row['Correlation_P_Value'] < 0.05 else ""
        print(f"{row['Property']:>12}: {row['Topological_Index']:>3} ({row['Scaling_Label']:>8}) "
              f"R²={row['LOOCV_R2']:6.3f}, RMSE={row['LOOCV_RMSE']:6.3f}, "
              f"MAE={row['LOOCV_MAE']:6.3f} {significance}")
        print(f"              Equation: y = {row['Final_Coefficient']:7.3f}*x + {row['Final_Intercept']:7.3f}")
    
   
    summary_filename = f'{output_dir}/LinearReg_summary_best_per_property.csv'
    summary_df.to_csv(summary_filename, index=False)
    print(f"\nSummary saved to: {summary_filename}")
    
   
    print(f"\nOverall Statistics Across All Properties:")
    print(f"  Mean LOOCV R²: {summary_df['LOOCV_R2'].mean():.4f}")
    print(f"  Mean LOOCV RMSE: {summary_df['LOOCV_RMSE'].mean():.4f}")
    print(f"  Mean LOOCV MAE: {summary_df['LOOCV_MAE'].mean():.4f}")
    print(f"  Properties analyzed: {len(summary_df)}")
    
    
    scaling_counts = summary_df['Scaling_Used'].value_counts()
    print(f"\nScaling Preference:")
    print(f"  Scaled models: {scaling_counts.get(True, 0)} properties")
    print(f"  Unscaled models: {scaling_counts.get(False, 0)} properties")
    
  
    significant_corr = summary_df['Correlation_P_Value'] < 0.05
    print(f"\nStatistical Significance (p < 0.05):")
    print(f"  Significant correlations: {significant_corr.sum()}/{len(summary_df)} properties")
    if significant_corr.any():
        print("  Significant properties:", summary_df[significant_corr]['Property'].tolist())
    
  
    print(f"\nCoefficient Analysis:")
    positive_coef = summary_df['Final_Coefficient'] > 0
    print(f"  Positive relationships: {positive_coef.sum()}/{len(summary_df)}")
    print(f"  Negative relationships: {(~positive_coef).sum()}/{len(summary_df)}")
    print(f"  Mean |coefficient|: {summary_df['Final_Coefficient'].abs().mean():.4f}")
    
    all_detailed = []
    for prop, results in detailed_results.items():
        all_detailed.extend(results)
    
    if all_detailed:
        comprehensive_df = pd.DataFrame(all_detailed)
        comprehensive_filename = f'{output_dir}'
        comprehensive_df.to_csv(comprehensive_filename, index=False)
        print(f"  Comprehensive results: {comprehensive_filename}")

else:
    print("No valid results found!")
    print("\nPossible issues:")
    print("1. Property columns don't exist in your CSV")
    print("2. Too many missing values")
    print("3. Data quality issues")

print(f"\nAll files saved in: {output_dir}")
print("\nLinear Regression Notes for 10-sample datasets:")
print("- Tests both scaled and unscaled features")
print("- Provides statistical significance tests")
print("- Shows linear equation for each relationship")
print("- LOOCV coefficient stability analysis")
print("- Correlation analysis included")
print("\nLinear Regression Advantages:")
print("- Highly interpretable coefficients")
print("- Fast training and prediction")
print("- No hyperparameters to tune")
print("- Clear linear relationships")
print("- Statistical significance testing")
print("- Baseline for other models")
print("\n** indicates statistically significant correlation (p < 0.05)")
print("\nAnalysis complete!")